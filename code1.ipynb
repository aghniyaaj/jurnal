{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import library"
      ],
      "metadata": {
        "id": "lQ-rzbLZP-Xq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKl_HBbuPb-n"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# CORE LIBRARIES\n",
        "# ===============================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ===============================\n",
        "# PREPROCESSING\n",
        "# ===============================\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ===============================\n",
        "# DEEP LEARNING\n",
        "# ===============================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ===============================\n",
        "# EVALUATION\n",
        "# ===============================\n",
        "from sklearn.metrics import mean_squared_error, confusion_matrix, classification_report\n",
        "\n",
        "# ===============================\n",
        "# REPRODUCIBILITY\n",
        "# ===============================\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD DATASET (REUSABLE)"
      ],
      "metadata": {
        "id": "cdHBVkfqQPCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh: load dataset CSV\n",
        "# Ganti path sesuai dataset Anda\n",
        "data_path = \"/content/drive/MyDrive/JST_TB/Dataset1/csv_result-chronic_kidney_disease.csv\"\n",
        "data = pd.read_csv(data_path, on_bad_lines='skip')\n",
        "\n",
        "# Clean column names: strip whitespace and remove single quotes\n",
        "data.columns = data.columns.str.strip().str.replace(\"'\", \"\")\n",
        "\n",
        "# Tampilkan 5 data awal\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-idwACygQR0P",
        "outputId": "f3bf4289-2601-45da-c556-bf5ffef35f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id age  bp     sg al su     rbc        pc         pcc          ba  ... pcv  \\\n",
              "0   1  48  80  1.020  1  0       ?    normal  notpresent  notpresent  ...  44   \n",
              "1   2   7  50  1.020  4  0       ?    normal  notpresent  notpresent  ...  38   \n",
              "2   3  62  80  1.010  2  3  normal    normal  notpresent  notpresent  ...  31   \n",
              "3   4  48  70  1.005  4  0  normal  abnormal     present  notpresent  ...  32   \n",
              "4   5  51  80  1.010  2  0  normal    normal  notpresent  notpresent  ...  35   \n",
              "\n",
              "   wbcc rbcc  htn   dm cad appet   pe  ane class  \n",
              "0  7800  5.2  yes  yes  no  good   no   no   ckd  \n",
              "1  6000    ?   no   no  no  good   no   no   ckd  \n",
              "2  7500    ?   no  yes  no  poor   no  yes   ckd  \n",
              "3  6700  3.9  yes   no  no  poor  yes  yes   ckd  \n",
              "4  7300  4.6   no   no  no  good   no   no   ckd  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d637bf1-7a1a-4f84-abd4-b68eaa2449fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>su</th>\n",
              "      <th>rbc</th>\n",
              "      <th>pc</th>\n",
              "      <th>pcc</th>\n",
              "      <th>ba</th>\n",
              "      <th>...</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wbcc</th>\n",
              "      <th>rbcc</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>appet</th>\n",
              "      <th>pe</th>\n",
              "      <th>ane</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>80</td>\n",
              "      <td>1.020</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>?</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>44</td>\n",
              "      <td>7800</td>\n",
              "      <td>5.2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>50</td>\n",
              "      <td>1.020</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>?</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>6000</td>\n",
              "      <td>?</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>62</td>\n",
              "      <td>80</td>\n",
              "      <td>1.010</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>31</td>\n",
              "      <td>7500</td>\n",
              "      <td>?</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>poor</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>48</td>\n",
              "      <td>70</td>\n",
              "      <td>1.005</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>present</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>6700</td>\n",
              "      <td>3.9</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>poor</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>51</td>\n",
              "      <td>80</td>\n",
              "      <td>1.010</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>35</td>\n",
              "      <td>7300</td>\n",
              "      <td>4.6</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d637bf1-7a1a-4f84-abd4-b68eaa2449fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d637bf1-7a1a-4f84-abd4-b68eaa2449fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d637bf1-7a1a-4f84-abd4-b68eaa2449fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9211f971-4f42-47ae-bdf8-de2c756cf2f9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9211f971-4f42-47ae-bdf8-de2c756cf2f9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9211f971-4f42-47ae-bdf8-de2c756cf2f9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PISAHKAN INPUT & TARGET (SESUAI JURNAL):"
      ],
      "metadata": {
        "id": "93Z6GK3ARV2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# INPUT & TARGET\n",
        "# ===============================\n",
        "\n",
        "# Daftar kolom kategorikal yang perlu di-mapping\n",
        "categorical_cols = [\n",
        "    'rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane'\n",
        "]\n",
        "\n",
        "# Mapping untuk nilai string ke numerik\n",
        "# Termasuk menangani '?' sebagai np.nan\n",
        "value_mapping = {\n",
        "    'yes': 1, 'no': 0,\n",
        "    'present': 1, 'notpresent': 0,\n",
        "    'normal': 1, 'abnormal': 0,\n",
        "    'good': 1, 'poor': 0,\n",
        "    'ckd': 1, 'notckd': 0,\n",
        "    '?': np.nan # Tangani '?' sebagai NaN\n",
        "}\n",
        "\n",
        "# Terapkan mapping pada kolom 'class' (target)\n",
        "data['class'] = data['class'].replace(value_mapping)\n",
        "\n",
        "# Terapkan mapping pada kolom kategorikal lainnya\n",
        "for col in categorical_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].replace(value_mapping)\n",
        "\n",
        "# Konversi semua kolom ke numerik. Jika ada nilai yang masih non-numerik, paksa jadi NaN.\n",
        "data = data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Membuang kolom 'id' yang tidak digunakan sebagai fitur\n",
        "data = data.drop(columns=['id'])\n",
        "\n",
        "# Pisahkan fitur (X) dan target (y)\n",
        "X = data.drop(columns=['class']).values\n",
        "y = data['class'].values\n",
        "\n",
        "print(\"Shape X:\", X.shape)\n",
        "print(\"Shape y:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK8UQhJuRYXF",
        "outputId": "ccbbfe7e-059a-46e2-8957-59812fbfeb0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X: (397, 24)\n",
            "Shape y: (397,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2229976259.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data['class'] = data['class'].replace(value_mapping)\n",
            "/tmp/ipython-input-2229976259.py:27: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data[col] = data[col].replace(value_mapping)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NORMALISASI DATA (MIN–MAX)"
      ],
      "metadata": {
        "id": "jwrphkFzRtLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Karena X sekarang seharusnya sudah numerik dengan NaN (dari pd.to_numeric),\n",
        "# kita perlu mengimputasi NaN sebelum scaling.\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Imputasi pada X (yang sudah diconvert ke numeric dan berisi NaN)\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scaling pada data yang sudah diimputasi\n",
        "X_scaled = scaler.fit_transform(X_imputed)"
      ],
      "metadata": {
        "id": "Lhe_gnIoRfaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLIT DATA (70–15–15) — SESUAI JURNAL"
      ],
      "metadata": {
        "id": "MYS2NrSUSJAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 70% training, 30% sementara\n",
        "# Gunakan y yang sudah di-encode dan X_scaled yang sudah diimputasi\n",
        "\n",
        "# Filter NaN dari y sebelum split data\n",
        "# Karena X_scaled sudah diimputasi, sekarang hanya perlu memastikan y tidak ada NaN.\n",
        "valid_mask_y = ~np.isnan(y)\n",
        "X_filtered_for_split = X_scaled[valid_mask_y]\n",
        "y_filtered_for_split = y[valid_mask_y]\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X_filtered_for_split, y_filtered_for_split, test_size=0.30, random_state=42\n",
        ")\n",
        "\n",
        "# 15% validation, 15% testing\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training:\", X_train.shape)\n",
        "print(\"Validation:\", X_val.shape)\n",
        "print(\"Testing:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCg1MxCqSPlR",
        "outputId": "62e46b70-e023-4a85-94b3-02d2d170c998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: (277, 24)\n",
            "Validation: (60, 24)\n",
            "Testing: (60, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NGUYEN–WIDROW INITIALIZATION (INTI JURNAL)"
      ],
      "metadata": {
        "id": "YaGDy5aJSR4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nguyen_widrow_init(n_input, n_hidden):\n",
        "    \"\"\"\n",
        "    Nguyen–Widrow initialization for hidden layer\n",
        "    \"\"\"\n",
        "    beta = 0.7 * (n_hidden ** (1 / n_input))\n",
        "\n",
        "    # Random weights\n",
        "    W = np.random.uniform(-0.5, 0.5, (n_input, n_hidden))\n",
        "\n",
        "    # Normalize weights\n",
        "    for i in range(n_hidden):\n",
        "        norm = np.linalg.norm(W[:, i])\n",
        "        W[:, i] = beta * W[:, i] / norm\n",
        "\n",
        "    # Bias\n",
        "    b = np.random.uniform(-beta, beta, n_hidden)\n",
        "\n",
        "    return W, b"
      ],
      "metadata": {
        "id": "hSDpAo_cSU31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BANGUN MODEL ANN (5–10–1)"
      ],
      "metadata": {
        "id": "ZVtFkafMSZ7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# BUILD MODEL\n",
        "# ===============================\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Hidden Layer (10 neuron)\n",
        "# Input dim harus sesuai dengan jumlah fitur di X setelah preprocessing\n",
        "model.add(Dense(\n",
        "    10,\n",
        "    input_dim=X.shape[1], # Sesuaikan input_dim dengan jumlah fitur baru dari X yang sudah diperbaiki\n",
        "    activation='sigmoid'\n",
        "))\n",
        "\n",
        "# Output Layer untuk klasifikasi biner (ckd/notckd)\n",
        "model.add(Dense(\n",
        "    1, # 1 neuron untuk klasifikasi biner\n",
        "    activation='sigmoid' # Sigmoid untuk klasifikasi biner\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T9w_LhvSane",
        "outputId": "afbcc5ea-6efe-4925-d216-e6c4cc634aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SET BOBOT NGUYEN–WIDROW KE MODEL"
      ],
      "metadata": {
        "id": "zOVtdHInSe88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Nguyen–Widrow to hidden layer\n",
        "# n_input harus disesuaikan dengan X.shape[1] yang baru\n",
        "W, b = nguyen_widrow_init(n_input=X.shape[1], n_hidden=10)\n",
        "model.layers[0].set_weights([W, b])"
      ],
      "metadata": {
        "id": "Fy4120P7ShuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMPILE MODEL"
      ],
      "metadata": {
        "id": "_xoJge1YSmHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',          # Pengganti trainlm\n",
        "    loss='binary_crossentropy', # Ganti ke binary_crossentropy untuk klasifikasi biner (0/1)\n",
        "    metrics=['accuracy'] # Gunakan accuracy untuk tugas klasifikasi\n",
        ")"
      ],
      "metadata": {
        "id": "Cz7ZuDYmSm4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING + EARLY STOPPING (VALIDATION CRITERION MET)"
      ],
      "metadata": {
        "id": "U_qoNBs9Ss45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karena X_train, X_val, y_train, y_val sudah bersih dari NaN dan dalam format numerik\n",
        "# dari langkah split data, penyaringan tambahan di sini tidak lagi diperlukan.\n",
        "\n",
        "# Calculate class weights to handle imbalance\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Pastikan kelas yang dihitung bobotnya adalah kelas unik dari y_train\n",
        "classes_in_train = np.unique(y_train)\n",
        "if len(classes_in_train) > 0:\n",
        "    class_weights = class_weight.compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=classes_in_train,\n",
        "        y=y_train\n",
        "    )\n",
        "    # Map class labels (0 dan 1) ke bobotnya\n",
        "    class_weights_dict = {int(i) : class_weights[idx] for idx, i in enumerate(classes_in_train)}\n",
        "else:\n",
        "    class_weights_dict = None # Atau tangani kasus tanpa kelas secara berbeda\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "# Memastikan X_train dan y_train tidak kosong sebelum fit\n",
        "if X_train.shape[0] > 0 and y_train.shape[0] > 0:\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=1000,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[early_stop],\n",
        "        class_weight=class_weights_dict,\n",
        "        verbose=1\n",
        "    )\n",
        "else:\n",
        "    print(\"Training or validation data is empty. Model training skipped.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj9MN665Stnt",
        "outputId": "37ee3a29-c239-42a4-b4da-5776860d8e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6397 - loss: 0.7208 - val_accuracy: 0.6000 - val_loss: 0.6570\n",
            "Epoch 2/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6397 - loss: 0.7030 - val_accuracy: 0.6000 - val_loss: 0.6494\n",
            "Epoch 3/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6397 - loss: 0.6884 - val_accuracy: 0.6000 - val_loss: 0.6431\n",
            "Epoch 4/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6397 - loss: 0.6756 - val_accuracy: 0.6000 - val_loss: 0.6376\n",
            "Epoch 5/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6397 - loss: 0.6645 - val_accuracy: 0.6000 - val_loss: 0.6327\n",
            "Epoch 6/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6397 - loss: 0.6546 - val_accuracy: 0.6000 - val_loss: 0.6282\n",
            "Epoch 7/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6397 - loss: 0.6457 - val_accuracy: 0.6000 - val_loss: 0.6237\n",
            "Epoch 8/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6397 - loss: 0.6375 - val_accuracy: 0.6333 - val_loss: 0.6192\n",
            "Epoch 9/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6645 - loss: 0.6299 - val_accuracy: 0.8667 - val_loss: 0.6145\n",
            "Epoch 10/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8754 - loss: 0.6227 - val_accuracy: 0.9833 - val_loss: 0.6096\n",
            "Epoch 11/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.6156 - val_accuracy: 0.9833 - val_loss: 0.6045\n",
            "Epoch 12/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9888 - loss: 0.6088 - val_accuracy: 0.9667 - val_loss: 0.5992\n",
            "Epoch 13/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9553 - loss: 0.6020 - val_accuracy: 0.9500 - val_loss: 0.5937\n",
            "Epoch 14/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9255 - loss: 0.5952 - val_accuracy: 0.9500 - val_loss: 0.5879\n",
            "Epoch 15/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9055 - loss: 0.5885 - val_accuracy: 0.9500 - val_loss: 0.5819\n",
            "Epoch 16/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9039 - loss: 0.5818 - val_accuracy: 0.9500 - val_loss: 0.5758\n",
            "Epoch 17/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9039 - loss: 0.5751 - val_accuracy: 0.9500 - val_loss: 0.5695\n",
            "Epoch 18/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9028 - loss: 0.5683 - val_accuracy: 0.9500 - val_loss: 0.5631\n",
            "Epoch 19/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9017 - loss: 0.5616 - val_accuracy: 0.9500 - val_loss: 0.5566\n",
            "Epoch 20/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9017 - loss: 0.5548 - val_accuracy: 0.9500 - val_loss: 0.5500\n",
            "Epoch 21/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9017 - loss: 0.5480 - val_accuracy: 0.9500 - val_loss: 0.5433\n",
            "Epoch 22/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9017 - loss: 0.5412 - val_accuracy: 0.9500 - val_loss: 0.5365\n",
            "Epoch 23/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9017 - loss: 0.5344 - val_accuracy: 0.9500 - val_loss: 0.5297\n",
            "Epoch 24/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9017 - loss: 0.5276 - val_accuracy: 0.9500 - val_loss: 0.5228\n",
            "Epoch 25/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8971 - loss: 0.5208 - val_accuracy: 0.9333 - val_loss: 0.5159\n",
            "Epoch 26/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.5140 - val_accuracy: 0.9333 - val_loss: 0.5090\n",
            "Epoch 27/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8971 - loss: 0.5073 - val_accuracy: 0.9167 - val_loss: 0.5021\n",
            "Epoch 28/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8956 - loss: 0.5006 - val_accuracy: 0.9167 - val_loss: 0.4952\n",
            "Epoch 29/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8956 - loss: 0.4940 - val_accuracy: 0.9167 - val_loss: 0.4883\n",
            "Epoch 30/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4874 - val_accuracy: 0.9167 - val_loss: 0.4814\n",
            "Epoch 31/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4808 - val_accuracy: 0.9167 - val_loss: 0.4746\n",
            "Epoch 32/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8971 - loss: 0.4744 - val_accuracy: 0.9167 - val_loss: 0.4678\n",
            "Epoch 33/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4680 - val_accuracy: 0.9167 - val_loss: 0.4610\n",
            "Epoch 34/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.4617 - val_accuracy: 0.9167 - val_loss: 0.4543\n",
            "Epoch 35/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.4554 - val_accuracy: 0.9167 - val_loss: 0.4477\n",
            "Epoch 36/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4493 - val_accuracy: 0.9333 - val_loss: 0.4411\n",
            "Epoch 37/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4432 - val_accuracy: 0.9333 - val_loss: 0.4346\n",
            "Epoch 38/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4372 - val_accuracy: 0.9333 - val_loss: 0.4281\n",
            "Epoch 39/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4314 - val_accuracy: 0.9333 - val_loss: 0.4218\n",
            "Epoch 40/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4256 - val_accuracy: 0.9333 - val_loss: 0.4155\n",
            "Epoch 41/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4199 - val_accuracy: 0.9333 - val_loss: 0.4093\n",
            "Epoch 42/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8971 - loss: 0.4143 - val_accuracy: 0.9333 - val_loss: 0.4033\n",
            "Epoch 43/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.4088 - val_accuracy: 0.9333 - val_loss: 0.3973\n",
            "Epoch 44/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.4035 - val_accuracy: 0.9333 - val_loss: 0.3914\n",
            "Epoch 45/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3982 - val_accuracy: 0.9333 - val_loss: 0.3856\n",
            "Epoch 46/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.3930 - val_accuracy: 0.9333 - val_loss: 0.3798\n",
            "Epoch 47/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3879 - val_accuracy: 0.9333 - val_loss: 0.3742\n",
            "Epoch 48/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3829 - val_accuracy: 0.9333 - val_loss: 0.3687\n",
            "Epoch 49/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3781 - val_accuracy: 0.9333 - val_loss: 0.3633\n",
            "Epoch 50/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3733 - val_accuracy: 0.9333 - val_loss: 0.3580\n",
            "Epoch 51/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8971 - loss: 0.3686 - val_accuracy: 0.9333 - val_loss: 0.3528\n",
            "Epoch 52/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3640 - val_accuracy: 0.9333 - val_loss: 0.3477\n",
            "Epoch 53/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3595 - val_accuracy: 0.9333 - val_loss: 0.3426\n",
            "Epoch 54/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3551 - val_accuracy: 0.9333 - val_loss: 0.3377\n",
            "Epoch 55/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.3508 - val_accuracy: 0.9333 - val_loss: 0.3329\n",
            "Epoch 56/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3465 - val_accuracy: 0.9333 - val_loss: 0.3282\n",
            "Epoch 57/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3424 - val_accuracy: 0.9333 - val_loss: 0.3236\n",
            "Epoch 58/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3383 - val_accuracy: 0.9333 - val_loss: 0.3190\n",
            "Epoch 59/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3344 - val_accuracy: 0.9333 - val_loss: 0.3146\n",
            "Epoch 60/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8971 - loss: 0.3305 - val_accuracy: 0.9333 - val_loss: 0.3102\n",
            "Epoch 61/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3267 - val_accuracy: 0.9333 - val_loss: 0.3060\n",
            "Epoch 62/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.3230 - val_accuracy: 0.9333 - val_loss: 0.3018\n",
            "Epoch 63/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.3193 - val_accuracy: 0.9333 - val_loss: 0.2977\n",
            "Epoch 64/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.3157 - val_accuracy: 0.9333 - val_loss: 0.2937\n",
            "Epoch 65/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3122 - val_accuracy: 0.9333 - val_loss: 0.2898\n",
            "Epoch 66/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3088 - val_accuracy: 0.9333 - val_loss: 0.2859\n",
            "Epoch 67/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3054 - val_accuracy: 0.9333 - val_loss: 0.2822\n",
            "Epoch 68/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.3021 - val_accuracy: 0.9333 - val_loss: 0.2785\n",
            "Epoch 69/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8971 - loss: 0.2989 - val_accuracy: 0.9333 - val_loss: 0.2749\n",
            "Epoch 70/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.2958 - val_accuracy: 0.9333 - val_loss: 0.2714\n",
            "Epoch 71/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.2927 - val_accuracy: 0.9333 - val_loss: 0.2679\n",
            "Epoch 72/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.2896 - val_accuracy: 0.9333 - val_loss: 0.2645\n",
            "Epoch 73/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.2866 - val_accuracy: 0.9333 - val_loss: 0.2612\n",
            "Epoch 74/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8971 - loss: 0.2837 - val_accuracy: 0.9333 - val_loss: 0.2580\n",
            "Epoch 75/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8987 - loss: 0.2809 - val_accuracy: 0.9333 - val_loss: 0.2548\n",
            "Epoch 76/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8987 - loss: 0.2781 - val_accuracy: 0.9333 - val_loss: 0.2517\n",
            "Epoch 77/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8987 - loss: 0.2753 - val_accuracy: 0.9333 - val_loss: 0.2486\n",
            "Epoch 78/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8987 - loss: 0.2726 - val_accuracy: 0.9333 - val_loss: 0.2456\n",
            "Epoch 79/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8987 - loss: 0.2700 - val_accuracy: 0.9333 - val_loss: 0.2427\n",
            "Epoch 80/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8987 - loss: 0.2674 - val_accuracy: 0.9333 - val_loss: 0.2399\n",
            "Epoch 81/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8987 - loss: 0.2648 - val_accuracy: 0.9333 - val_loss: 0.2370\n",
            "Epoch 82/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8987 - loss: 0.2623 - val_accuracy: 0.9333 - val_loss: 0.2343\n",
            "Epoch 83/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8987 - loss: 0.2598 - val_accuracy: 0.9333 - val_loss: 0.2316\n",
            "Epoch 84/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8987 - loss: 0.2574 - val_accuracy: 0.9333 - val_loss: 0.2289\n",
            "Epoch 85/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8987 - loss: 0.2551 - val_accuracy: 0.9333 - val_loss: 0.2263\n",
            "Epoch 86/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8987 - loss: 0.2527 - val_accuracy: 0.9333 - val_loss: 0.2238\n",
            "Epoch 87/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8987 - loss: 0.2504 - val_accuracy: 0.9333 - val_loss: 0.2213\n",
            "Epoch 88/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8987 - loss: 0.2482 - val_accuracy: 0.9333 - val_loss: 0.2188\n",
            "Epoch 89/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8987 - loss: 0.2460 - val_accuracy: 0.9333 - val_loss: 0.2164\n",
            "Epoch 90/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8987 - loss: 0.2438 - val_accuracy: 0.9333 - val_loss: 0.2141\n",
            "Epoch 91/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8987 - loss: 0.2417 - val_accuracy: 0.9333 - val_loss: 0.2117\n",
            "Epoch 92/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8987 - loss: 0.2396 - val_accuracy: 0.9333 - val_loss: 0.2095\n",
            "Epoch 93/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8987 - loss: 0.2375 - val_accuracy: 0.9333 - val_loss: 0.2072\n",
            "Epoch 94/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8987 - loss: 0.2355 - val_accuracy: 0.9333 - val_loss: 0.2050\n",
            "Epoch 95/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8987 - loss: 0.2335 - val_accuracy: 0.9333 - val_loss: 0.2029\n",
            "Epoch 96/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8987 - loss: 0.2316 - val_accuracy: 0.9500 - val_loss: 0.2008\n",
            "Epoch 97/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8987 - loss: 0.2296 - val_accuracy: 0.9500 - val_loss: 0.1987\n",
            "Epoch 98/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8987 - loss: 0.2277 - val_accuracy: 0.9500 - val_loss: 0.1967\n",
            "Epoch 99/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8987 - loss: 0.2259 - val_accuracy: 0.9500 - val_loss: 0.1946\n",
            "Epoch 100/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8987 - loss: 0.2240 - val_accuracy: 0.9500 - val_loss: 0.1927\n",
            "Epoch 101/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8987 - loss: 0.2222 - val_accuracy: 0.9500 - val_loss: 0.1907\n",
            "Epoch 102/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2204 - val_accuracy: 0.9500 - val_loss: 0.1888\n",
            "Epoch 103/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2187 - val_accuracy: 0.9500 - val_loss: 0.1870\n",
            "Epoch 104/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2169 - val_accuracy: 0.9500 - val_loss: 0.1851\n",
            "Epoch 105/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2152 - val_accuracy: 0.9500 - val_loss: 0.1833\n",
            "Epoch 106/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2135 - val_accuracy: 0.9500 - val_loss: 0.1815\n",
            "Epoch 107/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2119 - val_accuracy: 0.9500 - val_loss: 0.1798\n",
            "Epoch 108/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2103 - val_accuracy: 0.9500 - val_loss: 0.1780\n",
            "Epoch 109/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2087 - val_accuracy: 0.9500 - val_loss: 0.1763\n",
            "Epoch 110/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2071 - val_accuracy: 0.9500 - val_loss: 0.1747\n",
            "Epoch 111/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9100 - loss: 0.2055 - val_accuracy: 0.9500 - val_loss: 0.1730\n",
            "Epoch 112/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9100 - loss: 0.2040 - val_accuracy: 0.9500 - val_loss: 0.1714\n",
            "Epoch 113/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.2025 - val_accuracy: 0.9500 - val_loss: 0.1698\n",
            "Epoch 114/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.2010 - val_accuracy: 0.9500 - val_loss: 0.1682\n",
            "Epoch 115/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.1995 - val_accuracy: 0.9500 - val_loss: 0.1667\n",
            "Epoch 116/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9135 - loss: 0.1980 - val_accuracy: 0.9500 - val_loss: 0.1651\n",
            "Epoch 117/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.1966 - val_accuracy: 0.9500 - val_loss: 0.1636\n",
            "Epoch 118/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.1952 - val_accuracy: 0.9500 - val_loss: 0.1622\n",
            "Epoch 119/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.1938 - val_accuracy: 0.9500 - val_loss: 0.1607\n",
            "Epoch 120/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.1924 - val_accuracy: 0.9500 - val_loss: 0.1593\n",
            "Epoch 121/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9135 - loss: 0.1910 - val_accuracy: 0.9500 - val_loss: 0.1578\n",
            "Epoch 122/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9142 - loss: 0.1897 - val_accuracy: 0.9500 - val_loss: 0.1564\n",
            "Epoch 123/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9142 - loss: 0.1883 - val_accuracy: 0.9500 - val_loss: 0.1551\n",
            "Epoch 124/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.1870 - val_accuracy: 0.9500 - val_loss: 0.1537\n",
            "Epoch 125/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.1857 - val_accuracy: 0.9500 - val_loss: 0.1524\n",
            "Epoch 126/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.1844 - val_accuracy: 0.9500 - val_loss: 0.1510\n",
            "Epoch 127/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.1832 - val_accuracy: 0.9500 - val_loss: 0.1497\n",
            "Epoch 128/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.1819 - val_accuracy: 0.9500 - val_loss: 0.1484\n",
            "Epoch 129/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1807 - val_accuracy: 0.9500 - val_loss: 0.1472\n",
            "Epoch 130/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9230 - loss: 0.1795 - val_accuracy: 0.9500 - val_loss: 0.1459\n",
            "Epoch 131/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1783 - val_accuracy: 0.9500 - val_loss: 0.1447\n",
            "Epoch 132/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1771 - val_accuracy: 0.9500 - val_loss: 0.1434\n",
            "Epoch 133/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1759 - val_accuracy: 0.9500 - val_loss: 0.1422\n",
            "Epoch 134/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1747 - val_accuracy: 0.9500 - val_loss: 0.1410\n",
            "Epoch 135/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1736 - val_accuracy: 0.9500 - val_loss: 0.1399\n",
            "Epoch 136/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1724 - val_accuracy: 0.9500 - val_loss: 0.1387\n",
            "Epoch 137/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1713 - val_accuracy: 0.9500 - val_loss: 0.1375\n",
            "Epoch 138/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1702 - val_accuracy: 0.9500 - val_loss: 0.1364\n",
            "Epoch 139/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9230 - loss: 0.1691 - val_accuracy: 0.9500 - val_loss: 0.1353\n",
            "Epoch 140/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1680 - val_accuracy: 0.9500 - val_loss: 0.1342\n",
            "Epoch 141/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1669 - val_accuracy: 0.9500 - val_loss: 0.1331\n",
            "Epoch 142/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.1659 - val_accuracy: 0.9500 - val_loss: 0.1320\n",
            "Epoch 143/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9291 - loss: 0.1648 - val_accuracy: 0.9500 - val_loss: 0.1309\n",
            "Epoch 144/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9291 - loss: 0.1638 - val_accuracy: 0.9500 - val_loss: 0.1299\n",
            "Epoch 145/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9302 - loss: 0.1627 - val_accuracy: 0.9500 - val_loss: 0.1288\n",
            "Epoch 146/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9302 - loss: 0.1617 - val_accuracy: 0.9500 - val_loss: 0.1278\n",
            "Epoch 147/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9302 - loss: 0.1607 - val_accuracy: 0.9500 - val_loss: 0.1268\n",
            "Epoch 148/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9302 - loss: 0.1597 - val_accuracy: 0.9500 - val_loss: 0.1258\n",
            "Epoch 149/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9302 - loss: 0.1587 - val_accuracy: 0.9500 - val_loss: 0.1248\n",
            "Epoch 150/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9302 - loss: 0.1577 - val_accuracy: 0.9500 - val_loss: 0.1238\n",
            "Epoch 151/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9302 - loss: 0.1567 - val_accuracy: 0.9500 - val_loss: 0.1228\n",
            "Epoch 152/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9302 - loss: 0.1558 - val_accuracy: 0.9500 - val_loss: 0.1219\n",
            "Epoch 153/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9302 - loss: 0.1548 - val_accuracy: 0.9500 - val_loss: 0.1209\n",
            "Epoch 154/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9302 - loss: 0.1539 - val_accuracy: 0.9667 - val_loss: 0.1200\n",
            "Epoch 155/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9302 - loss: 0.1529 - val_accuracy: 0.9667 - val_loss: 0.1190\n",
            "Epoch 156/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1520 - val_accuracy: 0.9667 - val_loss: 0.1181\n",
            "Epoch 157/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9323 - loss: 0.1511 - val_accuracy: 0.9667 - val_loss: 0.1172\n",
            "Epoch 158/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1502 - val_accuracy: 0.9667 - val_loss: 0.1163\n",
            "Epoch 159/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1493 - val_accuracy: 0.9667 - val_loss: 0.1154\n",
            "Epoch 160/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1484 - val_accuracy: 0.9667 - val_loss: 0.1145\n",
            "Epoch 161/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1475 - val_accuracy: 0.9667 - val_loss: 0.1137\n",
            "Epoch 162/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1467 - val_accuracy: 0.9833 - val_loss: 0.1128\n",
            "Epoch 163/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1458 - val_accuracy: 0.9833 - val_loss: 0.1119\n",
            "Epoch 164/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1449 - val_accuracy: 0.9833 - val_loss: 0.1111\n",
            "Epoch 165/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9323 - loss: 0.1441 - val_accuracy: 0.9833 - val_loss: 0.1103\n",
            "Epoch 166/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1432 - val_accuracy: 0.9833 - val_loss: 0.1094\n",
            "Epoch 167/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1424 - val_accuracy: 0.9833 - val_loss: 0.1086\n",
            "Epoch 168/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1416 - val_accuracy: 0.9833 - val_loss: 0.1078\n",
            "Epoch 169/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1408 - val_accuracy: 0.9833 - val_loss: 0.1070\n",
            "Epoch 170/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.1400 - val_accuracy: 0.9833 - val_loss: 0.1062\n",
            "Epoch 171/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9415 - loss: 0.1392 - val_accuracy: 0.9833 - val_loss: 0.1054\n",
            "Epoch 172/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9415 - loss: 0.1384 - val_accuracy: 0.9833 - val_loss: 0.1046\n",
            "Epoch 173/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9415 - loss: 0.1376 - val_accuracy: 0.9833 - val_loss: 0.1039\n",
            "Epoch 174/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9415 - loss: 0.1368 - val_accuracy: 0.9833 - val_loss: 0.1031\n",
            "Epoch 175/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9415 - loss: 0.1360 - val_accuracy: 0.9833 - val_loss: 0.1023\n",
            "Epoch 176/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9415 - loss: 0.1352 - val_accuracy: 0.9833 - val_loss: 0.1016\n",
            "Epoch 177/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1345 - val_accuracy: 0.9833 - val_loss: 0.1009\n",
            "Epoch 178/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1337 - val_accuracy: 0.9833 - val_loss: 0.1001\n",
            "Epoch 179/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9442 - loss: 0.1330 - val_accuracy: 0.9833 - val_loss: 0.0994\n",
            "Epoch 180/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9442 - loss: 0.1322 - val_accuracy: 0.9833 - val_loss: 0.0987\n",
            "Epoch 181/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9442 - loss: 0.1315 - val_accuracy: 0.9833 - val_loss: 0.0980\n",
            "Epoch 182/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9442 - loss: 0.1308 - val_accuracy: 0.9833 - val_loss: 0.0973\n",
            "Epoch 183/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9442 - loss: 0.1300 - val_accuracy: 0.9833 - val_loss: 0.0966\n",
            "Epoch 184/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9442 - loss: 0.1293 - val_accuracy: 0.9833 - val_loss: 0.0959\n",
            "Epoch 185/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9442 - loss: 0.1286 - val_accuracy: 0.9833 - val_loss: 0.0952\n",
            "Epoch 186/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9442 - loss: 0.1279 - val_accuracy: 0.9833 - val_loss: 0.0945\n",
            "Epoch 187/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9442 - loss: 0.1272 - val_accuracy: 0.9833 - val_loss: 0.0938\n",
            "Epoch 188/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9442 - loss: 0.1265 - val_accuracy: 0.9833 - val_loss: 0.0932\n",
            "Epoch 189/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9442 - loss: 0.1258 - val_accuracy: 0.9833 - val_loss: 0.0925\n",
            "Epoch 190/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9442 - loss: 0.1251 - val_accuracy: 0.9833 - val_loss: 0.0919\n",
            "Epoch 191/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9442 - loss: 0.1245 - val_accuracy: 0.9833 - val_loss: 0.0912\n",
            "Epoch 192/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9442 - loss: 0.1238 - val_accuracy: 0.9833 - val_loss: 0.0906\n",
            "Epoch 193/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9442 - loss: 0.1231 - val_accuracy: 0.9833 - val_loss: 0.0900\n",
            "Epoch 194/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9442 - loss: 0.1225 - val_accuracy: 0.9833 - val_loss: 0.0893\n",
            "Epoch 195/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9442 - loss: 0.1218 - val_accuracy: 0.9833 - val_loss: 0.0887\n",
            "Epoch 196/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1211 - val_accuracy: 0.9833 - val_loss: 0.0881\n",
            "Epoch 197/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9442 - loss: 0.1205 - val_accuracy: 0.9833 - val_loss: 0.0875\n",
            "Epoch 198/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1199 - val_accuracy: 0.9833 - val_loss: 0.0869\n",
            "Epoch 199/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1192 - val_accuracy: 0.9833 - val_loss: 0.0863\n",
            "Epoch 200/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1186 - val_accuracy: 0.9833 - val_loss: 0.0857\n",
            "Epoch 201/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1180 - val_accuracy: 0.9833 - val_loss: 0.0851\n",
            "Epoch 202/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1173 - val_accuracy: 0.9833 - val_loss: 0.0845\n",
            "Epoch 203/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1167 - val_accuracy: 0.9833 - val_loss: 0.0839\n",
            "Epoch 204/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1161 - val_accuracy: 0.9833 - val_loss: 0.0834\n",
            "Epoch 205/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1155 - val_accuracy: 0.9833 - val_loss: 0.0828\n",
            "Epoch 206/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9442 - loss: 0.1149 - val_accuracy: 0.9833 - val_loss: 0.0822\n",
            "Epoch 207/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9442 - loss: 0.1143 - val_accuracy: 1.0000 - val_loss: 0.0817\n",
            "Epoch 208/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1137 - val_accuracy: 1.0000 - val_loss: 0.0811\n",
            "Epoch 209/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9463 - loss: 0.1131 - val_accuracy: 1.0000 - val_loss: 0.0806\n",
            "Epoch 210/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9463 - loss: 0.1126 - val_accuracy: 1.0000 - val_loss: 0.0801\n",
            "Epoch 211/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9463 - loss: 0.1120 - val_accuracy: 1.0000 - val_loss: 0.0795\n",
            "Epoch 212/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1114 - val_accuracy: 1.0000 - val_loss: 0.0790\n",
            "Epoch 213/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1108 - val_accuracy: 1.0000 - val_loss: 0.0785\n",
            "Epoch 214/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1103 - val_accuracy: 1.0000 - val_loss: 0.0779\n",
            "Epoch 215/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9474 - loss: 0.1097 - val_accuracy: 1.0000 - val_loss: 0.0774\n",
            "Epoch 216/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9474 - loss: 0.1092 - val_accuracy: 1.0000 - val_loss: 0.0769\n",
            "Epoch 217/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1086 - val_accuracy: 1.0000 - val_loss: 0.0764\n",
            "Epoch 218/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1081 - val_accuracy: 1.0000 - val_loss: 0.0759\n",
            "Epoch 219/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1075 - val_accuracy: 1.0000 - val_loss: 0.0754\n",
            "Epoch 220/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1070 - val_accuracy: 1.0000 - val_loss: 0.0749\n",
            "Epoch 221/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1064 - val_accuracy: 1.0000 - val_loss: 0.0744\n",
            "Epoch 222/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9501 - loss: 0.1059 - val_accuracy: 1.0000 - val_loss: 0.0740\n",
            "Epoch 223/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9528 - loss: 0.1054 - val_accuracy: 1.0000 - val_loss: 0.0735\n",
            "Epoch 224/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9620 - loss: 0.1049 - val_accuracy: 1.0000 - val_loss: 0.0730\n",
            "Epoch 225/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9620 - loss: 0.1043 - val_accuracy: 1.0000 - val_loss: 0.0725\n",
            "Epoch 226/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9620 - loss: 0.1038 - val_accuracy: 1.0000 - val_loss: 0.0721\n",
            "Epoch 227/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9620 - loss: 0.1033 - val_accuracy: 1.0000 - val_loss: 0.0716\n",
            "Epoch 228/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9620 - loss: 0.1028 - val_accuracy: 1.0000 - val_loss: 0.0712\n",
            "Epoch 229/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9620 - loss: 0.1023 - val_accuracy: 1.0000 - val_loss: 0.0707\n",
            "Epoch 230/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9620 - loss: 0.1018 - val_accuracy: 1.0000 - val_loss: 0.0703\n",
            "Epoch 231/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.1013 - val_accuracy: 1.0000 - val_loss: 0.0698\n",
            "Epoch 232/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9665 - loss: 0.1008 - val_accuracy: 1.0000 - val_loss: 0.0694\n",
            "Epoch 233/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.1003 - val_accuracy: 1.0000 - val_loss: 0.0689\n",
            "Epoch 234/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9665 - loss: 0.0998 - val_accuracy: 1.0000 - val_loss: 0.0685\n",
            "Epoch 235/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9665 - loss: 0.0994 - val_accuracy: 1.0000 - val_loss: 0.0681\n",
            "Epoch 236/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9665 - loss: 0.0989 - val_accuracy: 1.0000 - val_loss: 0.0676\n",
            "Epoch 237/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.0984 - val_accuracy: 1.0000 - val_loss: 0.0672\n",
            "Epoch 238/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.0979 - val_accuracy: 1.0000 - val_loss: 0.0668\n",
            "Epoch 239/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.0975 - val_accuracy: 1.0000 - val_loss: 0.0664\n",
            "Epoch 240/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.0970 - val_accuracy: 1.0000 - val_loss: 0.0660\n",
            "Epoch 241/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9665 - loss: 0.0965 - val_accuracy: 1.0000 - val_loss: 0.0656\n",
            "Epoch 242/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.0961 - val_accuracy: 1.0000 - val_loss: 0.0652\n",
            "Epoch 243/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9665 - loss: 0.0956 - val_accuracy: 1.0000 - val_loss: 0.0648\n",
            "Epoch 244/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.0952 - val_accuracy: 1.0000 - val_loss: 0.0644\n",
            "Epoch 245/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9665 - loss: 0.0947 - val_accuracy: 1.0000 - val_loss: 0.0640\n",
            "Epoch 246/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.0943 - val_accuracy: 1.0000 - val_loss: 0.0636\n",
            "Epoch 247/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0938 - val_accuracy: 1.0000 - val_loss: 0.0632\n",
            "Epoch 248/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0934 - val_accuracy: 1.0000 - val_loss: 0.0628\n",
            "Epoch 249/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0930 - val_accuracy: 1.0000 - val_loss: 0.0625\n",
            "Epoch 250/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.0925 - val_accuracy: 1.0000 - val_loss: 0.0621\n",
            "Epoch 251/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0921 - val_accuracy: 1.0000 - val_loss: 0.0617\n",
            "Epoch 252/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0917 - val_accuracy: 1.0000 - val_loss: 0.0613\n",
            "Epoch 253/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0912 - val_accuracy: 1.0000 - val_loss: 0.0610\n",
            "Epoch 254/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0908 - val_accuracy: 1.0000 - val_loss: 0.0606\n",
            "Epoch 255/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0904 - val_accuracy: 1.0000 - val_loss: 0.0603\n",
            "Epoch 256/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.0900 - val_accuracy: 1.0000 - val_loss: 0.0599\n",
            "Epoch 257/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0896 - val_accuracy: 1.0000 - val_loss: 0.0596\n",
            "Epoch 258/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.0892 - val_accuracy: 1.0000 - val_loss: 0.0592\n",
            "Epoch 259/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0888 - val_accuracy: 1.0000 - val_loss: 0.0589\n",
            "Epoch 260/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0883 - val_accuracy: 1.0000 - val_loss: 0.0585\n",
            "Epoch 261/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0879 - val_accuracy: 1.0000 - val_loss: 0.0582\n",
            "Epoch 262/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0875 - val_accuracy: 1.0000 - val_loss: 0.0578\n",
            "Epoch 263/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0872 - val_accuracy: 1.0000 - val_loss: 0.0575\n",
            "Epoch 264/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0868 - val_accuracy: 1.0000 - val_loss: 0.0572\n",
            "Epoch 265/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0864 - val_accuracy: 1.0000 - val_loss: 0.0568\n",
            "Epoch 266/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0860 - val_accuracy: 1.0000 - val_loss: 0.0565\n",
            "Epoch 267/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.0856 - val_accuracy: 1.0000 - val_loss: 0.0562\n",
            "Epoch 268/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0852 - val_accuracy: 1.0000 - val_loss: 0.0559\n",
            "Epoch 269/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.0848 - val_accuracy: 1.0000 - val_loss: 0.0556\n",
            "Epoch 270/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0845 - val_accuracy: 1.0000 - val_loss: 0.0553\n",
            "Epoch 271/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0841 - val_accuracy: 1.0000 - val_loss: 0.0549\n",
            "Epoch 272/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0837 - val_accuracy: 1.0000 - val_loss: 0.0546\n",
            "Epoch 273/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0833 - val_accuracy: 1.0000 - val_loss: 0.0543\n",
            "Epoch 274/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0830 - val_accuracy: 1.0000 - val_loss: 0.0540\n",
            "Epoch 275/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9711 - loss: 0.0826 - val_accuracy: 1.0000 - val_loss: 0.0537\n",
            "Epoch 276/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0822 - val_accuracy: 1.0000 - val_loss: 0.0534\n",
            "Epoch 277/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0819 - val_accuracy: 1.0000 - val_loss: 0.0531\n",
            "Epoch 278/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0815 - val_accuracy: 1.0000 - val_loss: 0.0528\n",
            "Epoch 279/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9711 - loss: 0.0812 - val_accuracy: 1.0000 - val_loss: 0.0526\n",
            "Epoch 280/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9711 - loss: 0.0808 - val_accuracy: 1.0000 - val_loss: 0.0523\n",
            "Epoch 281/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9711 - loss: 0.0805 - val_accuracy: 1.0000 - val_loss: 0.0520\n",
            "Epoch 282/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9711 - loss: 0.0801 - val_accuracy: 1.0000 - val_loss: 0.0517\n",
            "Epoch 283/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9711 - loss: 0.0798 - val_accuracy: 1.0000 - val_loss: 0.0514\n",
            "Epoch 284/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9711 - loss: 0.0794 - val_accuracy: 1.0000 - val_loss: 0.0511\n",
            "Epoch 285/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9711 - loss: 0.0791 - val_accuracy: 1.0000 - val_loss: 0.0509\n",
            "Epoch 286/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9711 - loss: 0.0788 - val_accuracy: 1.0000 - val_loss: 0.0506\n",
            "Epoch 287/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9711 - loss: 0.0784 - val_accuracy: 1.0000 - val_loss: 0.0503\n",
            "Epoch 288/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9711 - loss: 0.0781 - val_accuracy: 1.0000 - val_loss: 0.0501\n",
            "Epoch 289/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9711 - loss: 0.0777 - val_accuracy: 1.0000 - val_loss: 0.0498\n",
            "Epoch 290/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9711 - loss: 0.0774 - val_accuracy: 1.0000 - val_loss: 0.0495\n",
            "Epoch 291/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9711 - loss: 0.0771 - val_accuracy: 1.0000 - val_loss: 0.0493\n",
            "Epoch 292/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9711 - loss: 0.0768 - val_accuracy: 1.0000 - val_loss: 0.0490\n",
            "Epoch 293/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9711 - loss: 0.0764 - val_accuracy: 1.0000 - val_loss: 0.0488\n",
            "Epoch 294/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9711 - loss: 0.0761 - val_accuracy: 1.0000 - val_loss: 0.0485\n",
            "Epoch 295/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9711 - loss: 0.0758 - val_accuracy: 1.0000 - val_loss: 0.0482\n",
            "Epoch 296/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0755 - val_accuracy: 1.0000 - val_loss: 0.0480\n",
            "Epoch 297/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.0752 - val_accuracy: 1.0000 - val_loss: 0.0477\n",
            "Epoch 298/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0748 - val_accuracy: 1.0000 - val_loss: 0.0475\n",
            "Epoch 299/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0745 - val_accuracy: 1.0000 - val_loss: 0.0473\n",
            "Epoch 300/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0742 - val_accuracy: 1.0000 - val_loss: 0.0470\n",
            "Epoch 301/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0739 - val_accuracy: 1.0000 - val_loss: 0.0468\n",
            "Epoch 302/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0736 - val_accuracy: 1.0000 - val_loss: 0.0465\n",
            "Epoch 303/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0733 - val_accuracy: 1.0000 - val_loss: 0.0463\n",
            "Epoch 304/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0730 - val_accuracy: 1.0000 - val_loss: 0.0461\n",
            "Epoch 305/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0727 - val_accuracy: 1.0000 - val_loss: 0.0458\n",
            "Epoch 306/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.0724 - val_accuracy: 1.0000 - val_loss: 0.0456\n",
            "Epoch 307/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0721 - val_accuracy: 1.0000 - val_loss: 0.0454\n",
            "Epoch 308/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0718 - val_accuracy: 1.0000 - val_loss: 0.0452\n",
            "Epoch 309/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0715 - val_accuracy: 1.0000 - val_loss: 0.0449\n",
            "Epoch 310/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0712 - val_accuracy: 1.0000 - val_loss: 0.0447\n",
            "Epoch 311/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0709 - val_accuracy: 1.0000 - val_loss: 0.0445\n",
            "Epoch 312/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0706 - val_accuracy: 1.0000 - val_loss: 0.0443\n",
            "Epoch 313/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0704 - val_accuracy: 1.0000 - val_loss: 0.0441\n",
            "Epoch 314/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.0701 - val_accuracy: 1.0000 - val_loss: 0.0438\n",
            "Epoch 315/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0698 - val_accuracy: 1.0000 - val_loss: 0.0436\n",
            "Epoch 316/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0695 - val_accuracy: 1.0000 - val_loss: 0.0434\n",
            "Epoch 317/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0692 - val_accuracy: 1.0000 - val_loss: 0.0432\n",
            "Epoch 318/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0690 - val_accuracy: 1.0000 - val_loss: 0.0430\n",
            "Epoch 319/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0687 - val_accuracy: 1.0000 - val_loss: 0.0428\n",
            "Epoch 320/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0684 - val_accuracy: 1.0000 - val_loss: 0.0426\n",
            "Epoch 321/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0681 - val_accuracy: 1.0000 - val_loss: 0.0424\n",
            "Epoch 322/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0679 - val_accuracy: 1.0000 - val_loss: 0.0422\n",
            "Epoch 323/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.0676 - val_accuracy: 1.0000 - val_loss: 0.0420\n",
            "Epoch 324/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0673 - val_accuracy: 1.0000 - val_loss: 0.0418\n",
            "Epoch 325/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0671 - val_accuracy: 1.0000 - val_loss: 0.0416\n",
            "Epoch 326/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0668 - val_accuracy: 1.0000 - val_loss: 0.0414\n",
            "Epoch 327/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0665 - val_accuracy: 1.0000 - val_loss: 0.0412\n",
            "Epoch 328/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0663 - val_accuracy: 1.0000 - val_loss: 0.0410\n",
            "Epoch 329/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0660 - val_accuracy: 1.0000 - val_loss: 0.0408\n",
            "Epoch 330/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0657 - val_accuracy: 1.0000 - val_loss: 0.0406\n",
            "Epoch 331/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9772 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0405\n",
            "Epoch 332/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0652 - val_accuracy: 1.0000 - val_loss: 0.0403\n",
            "Epoch 333/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0650 - val_accuracy: 1.0000 - val_loss: 0.0401\n",
            "Epoch 334/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0647 - val_accuracy: 1.0000 - val_loss: 0.0399\n",
            "Epoch 335/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9772 - loss: 0.0645 - val_accuracy: 1.0000 - val_loss: 0.0397\n",
            "Epoch 336/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0642 - val_accuracy: 1.0000 - val_loss: 0.0395\n",
            "Epoch 337/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0640 - val_accuracy: 1.0000 - val_loss: 0.0394\n",
            "Epoch 338/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0637 - val_accuracy: 1.0000 - val_loss: 0.0392\n",
            "Epoch 339/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0635 - val_accuracy: 1.0000 - val_loss: 0.0390\n",
            "Epoch 340/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9772 - loss: 0.0632 - val_accuracy: 1.0000 - val_loss: 0.0388\n",
            "Epoch 341/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0630 - val_accuracy: 1.0000 - val_loss: 0.0387\n",
            "Epoch 342/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9772 - loss: 0.0628 - val_accuracy: 1.0000 - val_loss: 0.0385\n",
            "Epoch 343/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0625 - val_accuracy: 1.0000 - val_loss: 0.0383\n",
            "Epoch 344/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 0.0382\n",
            "Epoch 345/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0620 - val_accuracy: 1.0000 - val_loss: 0.0380\n",
            "Epoch 346/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0618 - val_accuracy: 1.0000 - val_loss: 0.0378\n",
            "Epoch 347/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0616 - val_accuracy: 1.0000 - val_loss: 0.0377\n",
            "Epoch 348/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9817 - loss: 0.0613 - val_accuracy: 1.0000 - val_loss: 0.0375\n",
            "Epoch 349/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0611 - val_accuracy: 1.0000 - val_loss: 0.0373\n",
            "Epoch 350/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0609 - val_accuracy: 1.0000 - val_loss: 0.0372\n",
            "Epoch 351/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0606 - val_accuracy: 1.0000 - val_loss: 0.0370\n",
            "Epoch 352/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0604 - val_accuracy: 1.0000 - val_loss: 0.0369\n",
            "Epoch 353/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0602 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
            "Epoch 354/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0600 - val_accuracy: 1.0000 - val_loss: 0.0366\n",
            "Epoch 355/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0597 - val_accuracy: 1.0000 - val_loss: 0.0364\n",
            "Epoch 356/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9824 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0363\n",
            "Epoch 357/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0593 - val_accuracy: 1.0000 - val_loss: 0.0361\n",
            "Epoch 358/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0591 - val_accuracy: 1.0000 - val_loss: 0.0360\n",
            "Epoch 359/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0588 - val_accuracy: 1.0000 - val_loss: 0.0358\n",
            "Epoch 360/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0586 - val_accuracy: 1.0000 - val_loss: 0.0357\n",
            "Epoch 361/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0584 - val_accuracy: 1.0000 - val_loss: 0.0355\n",
            "Epoch 362/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0582 - val_accuracy: 1.0000 - val_loss: 0.0354\n",
            "Epoch 363/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0580 - val_accuracy: 1.0000 - val_loss: 0.0352\n",
            "Epoch 364/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0578 - val_accuracy: 1.0000 - val_loss: 0.0351\n",
            "Epoch 365/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0575 - val_accuracy: 1.0000 - val_loss: 0.0349\n",
            "Epoch 366/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0573 - val_accuracy: 1.0000 - val_loss: 0.0348\n",
            "Epoch 367/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0571 - val_accuracy: 1.0000 - val_loss: 0.0346\n",
            "Epoch 368/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0569 - val_accuracy: 1.0000 - val_loss: 0.0345\n",
            "Epoch 369/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0567 - val_accuracy: 1.0000 - val_loss: 0.0344\n",
            "Epoch 370/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0565 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
            "Epoch 371/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0563 - val_accuracy: 1.0000 - val_loss: 0.0341\n",
            "Epoch 372/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0561 - val_accuracy: 1.0000 - val_loss: 0.0340\n",
            "Epoch 373/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0559 - val_accuracy: 1.0000 - val_loss: 0.0338\n",
            "Epoch 374/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0557 - val_accuracy: 1.0000 - val_loss: 0.0337\n",
            "Epoch 375/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0555 - val_accuracy: 1.0000 - val_loss: 0.0336\n",
            "Epoch 376/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9824 - loss: 0.0553 - val_accuracy: 1.0000 - val_loss: 0.0334\n",
            "Epoch 377/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9824 - loss: 0.0551 - val_accuracy: 1.0000 - val_loss: 0.0333\n",
            "Epoch 378/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9824 - loss: 0.0549 - val_accuracy: 1.0000 - val_loss: 0.0332\n",
            "Epoch 379/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9824 - loss: 0.0547 - val_accuracy: 1.0000 - val_loss: 0.0330\n",
            "Epoch 380/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9824 - loss: 0.0545 - val_accuracy: 1.0000 - val_loss: 0.0329\n",
            "Epoch 381/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9824 - loss: 0.0543 - val_accuracy: 1.0000 - val_loss: 0.0328\n",
            "Epoch 382/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9824 - loss: 0.0541 - val_accuracy: 1.0000 - val_loss: 0.0327\n",
            "Epoch 383/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9824 - loss: 0.0539 - val_accuracy: 1.0000 - val_loss: 0.0325\n",
            "Epoch 384/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9824 - loss: 0.0537 - val_accuracy: 1.0000 - val_loss: 0.0324\n",
            "Epoch 385/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9824 - loss: 0.0535 - val_accuracy: 1.0000 - val_loss: 0.0323\n",
            "Epoch 386/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9824 - loss: 0.0533 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
            "Epoch 387/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9824 - loss: 0.0531 - val_accuracy: 1.0000 - val_loss: 0.0320\n",
            "Epoch 388/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0529 - val_accuracy: 1.0000 - val_loss: 0.0319\n",
            "Epoch 389/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0527 - val_accuracy: 1.0000 - val_loss: 0.0318\n",
            "Epoch 390/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9824 - loss: 0.0526 - val_accuracy: 1.0000 - val_loss: 0.0317\n",
            "Epoch 391/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9824 - loss: 0.0524 - val_accuracy: 1.0000 - val_loss: 0.0316\n",
            "Epoch 392/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0522 - val_accuracy: 1.0000 - val_loss: 0.0315\n",
            "Epoch 393/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0520 - val_accuracy: 1.0000 - val_loss: 0.0313\n",
            "Epoch 394/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9824 - loss: 0.0518 - val_accuracy: 1.0000 - val_loss: 0.0312\n",
            "Epoch 395/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0516 - val_accuracy: 1.0000 - val_loss: 0.0311\n",
            "Epoch 396/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0514 - val_accuracy: 1.0000 - val_loss: 0.0310\n",
            "Epoch 397/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0513 - val_accuracy: 1.0000 - val_loss: 0.0309\n",
            "Epoch 398/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0511 - val_accuracy: 1.0000 - val_loss: 0.0308\n",
            "Epoch 399/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0509 - val_accuracy: 1.0000 - val_loss: 0.0307\n",
            "Epoch 400/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9869 - loss: 0.0507 - val_accuracy: 1.0000 - val_loss: 0.0305\n",
            "Epoch 401/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0505 - val_accuracy: 1.0000 - val_loss: 0.0304\n",
            "Epoch 402/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0504 - val_accuracy: 1.0000 - val_loss: 0.0303\n",
            "Epoch 403/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9869 - loss: 0.0502 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
            "Epoch 404/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0500 - val_accuracy: 1.0000 - val_loss: 0.0301\n",
            "Epoch 405/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0498 - val_accuracy: 1.0000 - val_loss: 0.0300\n",
            "Epoch 406/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0497 - val_accuracy: 1.0000 - val_loss: 0.0299\n",
            "Epoch 407/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0495 - val_accuracy: 1.0000 - val_loss: 0.0298\n",
            "Epoch 408/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0493 - val_accuracy: 1.0000 - val_loss: 0.0297\n",
            "Epoch 409/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9869 - loss: 0.0491 - val_accuracy: 1.0000 - val_loss: 0.0296\n",
            "Epoch 410/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0490 - val_accuracy: 1.0000 - val_loss: 0.0295\n",
            "Epoch 411/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0488 - val_accuracy: 1.0000 - val_loss: 0.0294\n",
            "Epoch 412/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0486 - val_accuracy: 1.0000 - val_loss: 0.0293\n",
            "Epoch 413/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0485 - val_accuracy: 1.0000 - val_loss: 0.0292\n",
            "Epoch 414/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0483 - val_accuracy: 1.0000 - val_loss: 0.0291\n",
            "Epoch 415/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0481 - val_accuracy: 1.0000 - val_loss: 0.0290\n",
            "Epoch 416/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0480 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
            "Epoch 417/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9869 - loss: 0.0478 - val_accuracy: 1.0000 - val_loss: 0.0288\n",
            "Epoch 418/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9869 - loss: 0.0476 - val_accuracy: 1.0000 - val_loss: 0.0287\n",
            "Epoch 419/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0475 - val_accuracy: 1.0000 - val_loss: 0.0286\n",
            "Epoch 420/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0473 - val_accuracy: 1.0000 - val_loss: 0.0285\n",
            "Epoch 421/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0471 - val_accuracy: 1.0000 - val_loss: 0.0284\n",
            "Epoch 422/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0470 - val_accuracy: 1.0000 - val_loss: 0.0283\n",
            "Epoch 423/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0468 - val_accuracy: 1.0000 - val_loss: 0.0282\n",
            "Epoch 424/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0467 - val_accuracy: 1.0000 - val_loss: 0.0281\n",
            "Epoch 425/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9869 - loss: 0.0465 - val_accuracy: 1.0000 - val_loss: 0.0280\n",
            "Epoch 426/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0463 - val_accuracy: 1.0000 - val_loss: 0.0279\n",
            "Epoch 427/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0462 - val_accuracy: 1.0000 - val_loss: 0.0278\n",
            "Epoch 428/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0460 - val_accuracy: 1.0000 - val_loss: 0.0277\n",
            "Epoch 429/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9869 - loss: 0.0459 - val_accuracy: 1.0000 - val_loss: 0.0276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUASI MODEL"
      ],
      "metadata": {
        "id": "4GMqPYOrT1II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test dan y_test sudah bersih dari NaN dan dalam format numerik dari langkah split data.\n",
        "\n",
        "y_pred_raw = model.predict(X_test)\n",
        "# Untuk klasifikasi biner, kita thresholding output sigmoid (probabilitas)\n",
        "# Jika probabilitas > 0.5, prediksi kelas 1, jika tidak, prediksi kelas 0\n",
        "y_pred = (y_pred_raw > 0.5).astype(int).flatten() # Flatten untuk memastikan 1D array\n",
        "\n",
        "# Metrik MSE tidak relevan lagi untuk klasifikasi biner untuk klasifikasi biner\n",
        "# mse = mean_squared_error(y_test, y_pred)\n",
        "# print(\"MSE Test:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKtlTyq9T179",
        "outputId": "7e789def-b5b8-4aaa-8473-38f74810dc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFUSION MATRIX & CLASSIFICATION REPORT"
      ],
      "metadata": {
        "id": "kUdLnMC3UZH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YAwmAPhUlQ1",
        "outputId": "8dd9eea9-bc2b-4809-f26a-9d2eaf8e3f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[25  0]\n",
            " [ 1 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        25\n",
            "           1       1.00      0.97      0.99        35\n",
            "\n",
            "    accuracy                           0.98        60\n",
            "   macro avg       0.98      0.99      0.98        60\n",
            "weighted avg       0.98      0.98      0.98        60\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KESIMPULAN\n",
        "\n",
        "Penelitian ini menerapkan metode Jaringan Saraf Tiruan (Artificial Neural\n",
        "\n",
        "\n",
        "Network) dengan satu lapisan tersembunyi menggunakan algoritma Backpropagation dan inisialisasi bobot Nguyen–Widrow pada dataset csv_result-chronic_kidney_disease.csv.\n",
        "\n",
        "Dataset yang digunakan merupakan dataset medis Chronic Kidney Disease (CKD) dengan karakteristik klasifikasi biner, sehingga dilakukan penyesuaian pada tahap pemodelan tanpa mengubah struktur dasar jaringan saraf tiruan yang mengacu pada jurnal rujukan.\n",
        "\n",
        "Hasil pengujian menunjukkan bahwa model JST mampu mencapai tingkat akurasi sebesar 98% pada data pengujian, dengan performa klasifikasi yang sangat baik pada kedua kelas, yaitu CKD dan non-CKD.\n",
        "\n",
        "Analisis confusion matrix memperlihatkan bahwa model hanya melakukan satu kesalahan klasifikasi dari total 60 data uji, serta menghasilkan nilai precision, recall, dan F1-score yang tinggi dan seimbang.\n",
        "\n",
        "Proses pelatihan jaringan berhenti pada epoch ke-400, yang menandakan bahwa nilai validation loss masih mengalami perbaikan hingga titik tersebut dan model melakukan proses optimisasi secara stabil.\n",
        "\n",
        "Penggunaan mekanisme early stopping membantu mencegah terjadinya overfitting dan memastikan bahwa bobot terbaik digunakan pada proses evaluasi model.\n",
        "\n",
        "Secara metodologis, penelitian ini tetap mempertahankan prinsip utama dari jurnal rujukan, yaitu arsitektur ANN, algoritma Backpropagation, dan inisialisasi bobot Nguyen–Widrow, meskipun dilakukan adaptasi pada fungsi keluaran dan metrik evaluasi.\n",
        "\n",
        "Dengan demikian, metode ANN dengan inisialisasi Nguyen–Widrow terbukti tetap efektif dan relevan ketika diterapkan pada dataset medis yang lebih kompleks, asalkan dilakukan penyesuaian yang sesuai dengan karakteristik data.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iVIImzUZ5xPK"
      }
    }
  ]
}